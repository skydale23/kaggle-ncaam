{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sample dataset\n",
    "test = pd.read_csv('../../data/MSampleSubmissionStage1_2020.csv')\n",
    "test = process_sample_sub(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed data\n",
    "all_games = pd.read_csv('../feature_engineering/output/all_games.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>avg_rank_x</th>\n",
       "      <th>t1_final_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_OrdinalRank</th>\n",
       "      <th>t1_pre_season_top_25_flag</th>\n",
       "      <th>t2_OrdinalRank</th>\n",
       "      <th>t2_pre_season_top_25_flag</th>\n",
       "      <th>t1_adj_oe_0</th>\n",
       "      <th>t1_adj_de_0</th>\n",
       "      <th>t2_adj_oe_0</th>\n",
       "      <th>t2_adj_de_0</th>\n",
       "      <th>t1_adj_margin</th>\n",
       "      <th>t2_adj_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1421_1411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1421</td>\n",
       "      <td>1411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237</td>\n",
       "      <td>67.338190</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.526528</td>\n",
       "      <td>119.437414</td>\n",
       "      <td>106.509926</td>\n",
       "      <td>111.907479</td>\n",
       "      <td>-14.910886</td>\n",
       "      <td>-5.397553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1112_1436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1112</td>\n",
       "      <td>1436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95.514642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.071254</td>\n",
       "      <td>93.286794</td>\n",
       "      <td>106.884988</td>\n",
       "      <td>101.850357</td>\n",
       "      <td>25.784460</td>\n",
       "      <td>5.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1113_1272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1113</td>\n",
       "      <td>1272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>84.233153</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.219248</td>\n",
       "      <td>101.541410</td>\n",
       "      <td>114.009765</td>\n",
       "      <td>96.248862</td>\n",
       "      <td>19.677837</td>\n",
       "      <td>17.760903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1141_1166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1141</td>\n",
       "      <td>1166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>84.559424</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.038016</td>\n",
       "      <td>105.370558</td>\n",
       "      <td>117.078846</td>\n",
       "      <td>97.251061</td>\n",
       "      <td>7.667458</td>\n",
       "      <td>19.827785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1143_1301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1143</td>\n",
       "      <td>1301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>84.394558</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.121076</td>\n",
       "      <td>101.087582</td>\n",
       "      <td>116.019889</td>\n",
       "      <td>102.254106</td>\n",
       "      <td>10.033494</td>\n",
       "      <td>13.765783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type              ID  Pred  Season  Team1  Team2  Outcome  \\\n",
       "0           0     0  2003_1421_1411   NaN    2003   1421   1411      1.0   \n",
       "1           1     0  2003_1112_1436   NaN    2003   1112   1436      1.0   \n",
       "2           2     0  2003_1113_1272   NaN    2003   1113   1272      1.0   \n",
       "3           3     0  2003_1141_1166   NaN    2003   1141   1166      1.0   \n",
       "4           4     0  2003_1143_1301   NaN    2003   1143   1301      1.0   \n",
       "\n",
       "   avg_rank_x  t1_final_rank  ...  t1_OrdinalRank  t1_pre_season_top_25_flag  \\\n",
       "0         237      67.338190  ...            25.0                        NaN   \n",
       "1           2      95.514642  ...             1.0                        1.0   \n",
       "2          34      84.233153  ...            25.0                        NaN   \n",
       "3          32      84.559424  ...            25.0                        NaN   \n",
       "4          33      84.394558  ...            25.0                        NaN   \n",
       "\n",
       "   t2_OrdinalRank  t2_pre_season_top_25_flag  t1_adj_oe_0  t1_adj_de_0  \\\n",
       "0            25.0                        NaN   104.526528   119.437414   \n",
       "1            25.0                        NaN   119.071254    93.286794   \n",
       "2            25.0                        NaN   121.219248   101.541410   \n",
       "3            23.0                        1.0   113.038016   105.370558   \n",
       "4            25.0                        NaN   111.121076   101.087582   \n",
       "\n",
       "   t2_adj_oe_0  t2_adj_de_0  t1_adj_margin  t2_adj_margin  \n",
       "0   106.509926   111.907479     -14.910886      -5.397553  \n",
       "1   106.884988   101.850357      25.784460       5.034632  \n",
       "2   114.009765    96.248862      19.677837      17.760903  \n",
       "3   117.078846    97.251061       7.667458      19.827785  \n",
       "4   116.019889   102.254106      10.033494      13.765783  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tournament games we are predicting on \n",
    "all_games = all_games[(all_games.Season < 2015)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'type', 'ID', 'Pred', 'Season', 'Team1', 'Team2',\n",
       "       'Outcome', 'avg_rank_x', 't1_final_rank', 'avg_rank_y', 't2_final_rank',\n",
       "       't1_Seed', 't2_Seed', 'seed_diff', 't1_OrdinalRank',\n",
       "       't1_pre_season_top_25_flag', 't2_OrdinalRank',\n",
       "       't2_pre_season_top_25_flag', 't1_adj_oe_0', 't1_adj_de_0',\n",
       "       't2_adj_oe_0', 't2_adj_de_0', 't1_adj_margin', 't2_adj_margin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['seed_diff',  \n",
    "                't1_adj_margin','t2_adj_margin',\n",
    "                't1_final_rank', 't2_final_rank',\n",
    "                't1_OrdinalRank', 't2_OrdinalRank',\n",
    "               ]\n",
    " \n",
    "#feature_list = ['t1_adj_oe', 't2_adj_oe', 't1_adj_de', 't2_adj_de', 't1_adj_oe_120_999', 't2_adj_oe_120_999', 't1_adj_de_120_999', 't2_adj_de_120_999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = all_games.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_games[feature_list].values\n",
    "y = all_games['Outcome'].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search to get best params\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=9), 'penalty': ['l2', 'l1']}\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "#Use best params to train final model\n",
    "logreg = LogisticRegression(**best_param)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate score on test set \n",
    "#y_pred = logreg.predict_proba(X_test)\n",
    "#log_loss(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Pipeline([('scale', StandardScaler()),('logreg', LogisticRegression(**best_param))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. log loss: 0.5357415850410531\n",
      "min log loss: 0.4514395461214332\n",
      "max log loss: 0.627651988416418\n",
      "std dev log loss: 0.04843936979238789\n",
      "[0.5237920042565816, 0.5300941586898208, 0.5119495443359925, 0.5633991102726171, 0.4514395461214332, 0.4803304744910474, 0.49226181467464325, 0.536909874468868, 0.627651988416418, 0.5591074889268227, 0.5772740688201984, 0.5746889470181937]\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "seasons = list(all_games.Season.unique())\n",
    "\n",
    "log_loss_list = []\n",
    "\n",
    "for test_season in seasons:\n",
    "    \n",
    "    train_seasons = seasons.copy()\n",
    "    train_seasons.remove(test_season)\n",
    " \n",
    "    X_train = all_games[all_games['Season'].isin(train_seasons)][feature_list].values\n",
    "    X_test = all_games[all_games.Season == test_season][feature_list].values\n",
    "\n",
    "    y_train = all_games[all_games['Season'].isin(train_seasons)]['Outcome'].values.ravel()\n",
    "    y_test = all_games[all_games.Season == test_season]['Outcome'].values.ravel()\n",
    "    \n",
    "    logreg = LogisticRegression(**best_param)\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    #Evaluate score on test set \n",
    "    y_pred = logreg.predict_proba(X_test)\n",
    "    \n",
    "    ll = log_loss(y_test, y_pred)\n",
    "    log_loss_list.append(ll)\n",
    "    \n",
    "    \n",
    "print('avg. log loss: {}'.format(sum(log_loss_list) / len(log_loss_list)))\n",
    "print('min log loss: {}'.format(min(log_loss_list)))\n",
    "print('max log loss: {}'.format(max(log_loss_list)))\n",
    "print('std dev log loss: {}'.format(statistics.stdev(log_loss_list)))\n",
    "print(log_loss_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on entire dataset\n",
    "logreg = LogisticRegression(**best_param)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg. log loss: 0.5377196208726289\n",
    "min log loss: 0.4527681615412048\n",
    "max log loss: 0.6301372973190598\n",
    "std dev log loss: 0.04826156092665253\n",
    "[0.5229902686047858, 0.5236486146281775, 0.5158111793350595, 0.56923309326896, 0.4527681615412048, 0.483523972814316, 0.5005711494650689, 0.5390678057159176, 0.6301372973190598, 0.562545719196487, 0.5826151696256913, 0.5697230189568193]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search to get best params\n",
    "clf = XGBClassifier(random_state = 0)\n",
    "\n",
    "params = {'min_child_weight': [5],\n",
    "        'gamma': [5, 10],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.4, 0.6],\n",
    "        'max_depth': [1, 2, 3, 10, 20, 30, 50]\n",
    "        }\n",
    "\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'colsample_bytree': 0.8,                 \n",
    "              'learning_rate': 0.0003,\n",
    "              'max_depth': 5,\n",
    "              'subsample': 1,\n",
    "              'objective':'binary:logistic',\n",
    "              'eval_metric':'logloss',\n",
    "              'min_child_weight':3,\n",
    "              'gamma':0.25,\n",
    "              'n_estimators':500,\n",
    "              'verbosity':5\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. log loss: 0.6614626711755712\n",
      "min log loss: 0.6542309042997658\n",
      "max log loss: 0.670325395331454\n",
      "std dev log loss: 0.005667239934436234\n",
      "[0.6589280436746776, 0.6597465183585882, 0.6566117340698838, 0.6678383476100862, 0.654261922929436, 0.6572385858744383, 0.6542309042997658, 0.6642895918339491, 0.669623213472651, 0.6609168021536586, 0.6635409944982671, 0.670325395331454]\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "seasons = list(all_games.Season.unique())\n",
    "\n",
    "log_loss_list = []\n",
    "\n",
    "for test_season in seasons:\n",
    "    \n",
    "    train_seasons = seasons.copy()\n",
    "    train_seasons.remove(test_season)\n",
    " \n",
    "    X_train = all_games[all_games['Season'].isin(train_seasons)][feature_list].values\n",
    "    X_test = all_games[all_games.Season == test_season][feature_list].values\n",
    "\n",
    "    y_train = all_games[all_games['Season'].isin(train_seasons)]['Outcome'].values.ravel()\n",
    "    y_test = all_games[all_games.Season == test_season]['Outcome'].values.ravel()\n",
    "    \n",
    "    clf = XGBClassifier(**best_param)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Evaluate score on test set \n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    ll = log_loss(y_test, y_pred)\n",
    "    log_loss_list.append(ll)\n",
    "    \n",
    "    \n",
    "print('avg. log loss: {}'.format(sum(log_loss_list) / len(log_loss_list)))\n",
    "print('min log loss: {}'.format(min(log_loss_list)))\n",
    "print('max log loss: {}'.format(max(log_loss_list)))\n",
    "print('std dev log loss: {}'.format(statistics.stdev(log_loss_list)))\n",
    "print(log_loss_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg. log loss: 0.5382626508307115\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 1618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfrom sklearn import svm\\nCs = [0.001, 0.01, 0.1, 1, 10]\\ngammas = [0.001, 0.01, 0.1, 1]\\nparam_grid = {'C': Cs, 'gamma' : gammas}\\nclf = GridSearchCV(svm.SVC(kernel='rbf', probability = True), param_grid, cv=5)\\nclf.fit(X, y)\\nclf.fit(X_train, y_train)\\nbest_param = clf.best_params_\\n\\n\\nsvc_ = svm.SVC(**best_param, probability = True)\\nsvc_.fit(X_train, y_train)\\n\\ny_pred = svc_.predict_proba(X_test)\\nlog_loss(y_test, y_pred)\\n\""
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "from sklearn import svm\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "clf = GridSearchCV(svm.SVC(kernel='rbf', probability = True), param_grid, cv=5)\n",
    "clf.fit(X, y)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "\n",
    "svc_ = svm.SVC(**best_param, probability = True)\n",
    "svc_.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_.predict_proba(X_test)\n",
    "log_loss(y_test, y_pred)\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. log loss: 0.531922722936705\n",
      "min log loss: 0.4445775307006808\n",
      "max log loss: 0.6229365622303814\n",
      "std dev log loss: 0.048389749307892846\n",
      "[0.5226171255883458, 0.5260895194839206, 0.5105384202401526, 0.5587125165429248, 0.4445775307006808, 0.47792357220814596, 0.4882708443748359, 0.5332024572220709, 0.6229365622303814, 0.5538069505726807, 0.5733605436225888, 0.5710366324537309]\n"
     ]
    }
   ],
   "source": [
    "#Grid search to get best params\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "params = {'min_samples_leaf': [1, 5, 15, 25, 50, 80, 100], \n",
    "          'bootstrap': [True, False],\n",
    "          'max_depth': [1, 3, 5, 10, 20, None],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "         }\n",
    "\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "#Cross validation\n",
    "seasons = list(all_games.Season.unique())\n",
    "\n",
    "log_loss_list = []\n",
    "\n",
    "for test_season in seasons:\n",
    "    \n",
    "    train_seasons = seasons.copy()\n",
    "    train_seasons.remove(test_season)\n",
    " \n",
    "    X_train = all_games[all_games['Season'].isin(train_seasons)][feature_list].values\n",
    "    X_test = all_games[all_games.Season == test_season][feature_list].values\n",
    "\n",
    "    y_train = all_games[all_games['Season'].isin(train_seasons)]['Outcome'].values.ravel()\n",
    "    y_test = all_games[all_games.Season == test_season]['Outcome'].values.ravel()\n",
    "    \n",
    "    rf = RandomForestClassifier(**best_param)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Evaluate score on test set \n",
    "    y_pred = logreg.predict_proba(X_test)\n",
    "    \n",
    "    ll = log_loss(y_test, y_pred)\n",
    "    log_loss_list.append(ll)\n",
    "    \n",
    "    \n",
    "print('avg. log loss: {}'.format(sum(log_loss_list) / len(log_loss_list)))\n",
    "print('min log loss: {}'.format(min(log_loss_list)))\n",
    "print('max log loss: {}'.format(max(log_loss_list)))\n",
    "print('std dev log loss: {}'.format(statistics.stdev(log_loss_list)))\n",
    "print(log_loss_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=25, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=80, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on entire dataset\n",
    "rf = RandomForestClassifier(**best_param)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games.to_csv('output/all_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "with open(\"model/logreg.pkl\", \"wb\") as file: \n",
    "    pickle.dump(logreg, file)\n",
    "\n",
    "with open(\"model/rf.pkl\", \"wb\") as file: \n",
    "    pickle.dump(rf, file)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
