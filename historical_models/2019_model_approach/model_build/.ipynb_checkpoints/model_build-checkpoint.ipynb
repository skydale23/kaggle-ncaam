{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sample dataset\n",
    "test = pd.read_csv('../../data/MSampleSubmissionStage1_2020.csv')\n",
    "test = process_sample_sub(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed data\n",
    "all_games = pd.read_csv('../feature_engineering/output/all_games.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tournament games we are predicting on \n",
    "all_games = all_games[((all_games.Season >= 2015) & (all_games.TourneyGame == 0))\n",
    "                  | (all_games.Season < 2015)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear model to predict efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize='True')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train linear model\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#measures of how your performance, your opp's performance and both of your historical competitions\n",
    "reg_feature_list = ['Team1_avg_oe', 'Team1_avg_de','Team1_avg_opp_avg_oe','Team1_avg_opp_avg_de',\n",
    "                           'Team1_avg_opp_avg_opp_avg_oe', 'Team1_avg_opp_avg_opp_avg_de',\n",
    "                            'Team1_avg_opp_avg_opp_avg_opp_avg_oe', 'Team1_avg_opp_avg_opp_avg_opp_avg_de',\n",
    "                           'Team1_avg_opp_avg_opp_avg_opp_avg_opp_avg_oe',\n",
    "                               'Team1_avg_opp_avg_opp_avg_opp_avg_opp_avg_de',\n",
    "                    \n",
    "                   'Team2_avg_oe', 'Team2_avg_de','Team2_avg_opp_avg_oe','Team2_avg_opp_avg_de',\n",
    "                           'Team2_avg_opp_avg_opp_avg_oe', 'Team2_avg_opp_avg_opp_avg_de',\n",
    "                            'Team2_avg_opp_avg_opp_avg_opp_avg_oe', 'Team2_avg_opp_avg_opp_avg_opp_avg_de',\n",
    "                           'Team2_avg_opp_avg_opp_avg_opp_avg_opp_avg_oe',\n",
    "                               'Team2_avg_opp_avg_opp_avg_opp_avg_opp_avg_de']\n",
    "\n",
    "all_games = all_games.dropna(subset = reg_feature_list)\n",
    "\n",
    "df = all_games.copy()\n",
    "\n",
    "#OE model\n",
    "y = 'Team1_OffRtg'\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "X_full = df[reg_feature_list].values\n",
    "y_full = df[y].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[reg_feature_list], df[y], test_size = .2, random_state = 0)\n",
    "\n",
    "oe_model = linear_model.LinearRegression(normalize = 'True')\n",
    "oe_model.fit(X_train, y_train)\n",
    "\n",
    "#DE Model\n",
    "y = 'Team1_DefRtg'\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "X_full = df[reg_feature_list].values\n",
    "y_full = df[y].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[reg_feature_list], df[y], test_size = .2, random_state = 0)\n",
    "\n",
    "de_model = linear_model.LinearRegression(normalize = 'True')\n",
    "de_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games['t1_pred_oe'] = oe_model.predict(all_games[reg_feature_list].values)\n",
    "all_games['t1_pred_de'] = de_model.predict(all_games[reg_feature_list].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_games[all_games.TourneyGame == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic model to predict %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>TourneyGame</th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Team1_score</th>\n",
       "      <th>Team2_score</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>...</th>\n",
       "      <th>Team2_avg_opp_avg_opp_avg_opp_avg_oe</th>\n",
       "      <th>Team2_avg_opp_avg_opp_avg_opp_avg_de</th>\n",
       "      <th>Team2_opp_avg_opp_avg_opp_avg_opp_avg_oe</th>\n",
       "      <th>Team2_opp_avg_opp_avg_opp_avg_opp_avg_de</th>\n",
       "      <th>Team2_avg_opp_avg_opp_avg_opp_avg_opp_avg_oe</th>\n",
       "      <th>Team2_avg_opp_avg_opp_avg_opp_avg_opp_avg_de</th>\n",
       "      <th>Team2_Seed</th>\n",
       "      <th>Seed_Diff</th>\n",
       "      <th>t1_pred_oe</th>\n",
       "      <th>t1_pred_de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>137</td>\n",
       "      <td>1104</td>\n",
       "      <td>1231</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>105.644309</td>\n",
       "      <td>100.708799</td>\n",
       "      <td>105.240340</td>\n",
       "      <td>101.246967</td>\n",
       "      <td>104.395899</td>\n",
       "      <td>102.682732</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>109.064224</td>\n",
       "      <td>109.987823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1112</td>\n",
       "      <td>1436</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>100.841206</td>\n",
       "      <td>104.400967</td>\n",
       "      <td>105.225967</td>\n",
       "      <td>101.301322</td>\n",
       "      <td>102.396114</td>\n",
       "      <td>103.091542</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "      <td>115.220135</td>\n",
       "      <td>99.533473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>138</td>\n",
       "      <td>1112</td>\n",
       "      <td>1211</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>102.784377</td>\n",
       "      <td>103.030696</td>\n",
       "      <td>105.106742</td>\n",
       "      <td>101.446902</td>\n",
       "      <td>102.546447</td>\n",
       "      <td>103.239985</td>\n",
       "      <td>9</td>\n",
       "      <td>-8</td>\n",
       "      <td>113.888298</td>\n",
       "      <td>105.714808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>143</td>\n",
       "      <td>1112</td>\n",
       "      <td>1323</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>106.672656</td>\n",
       "      <td>100.302686</td>\n",
       "      <td>105.089853</td>\n",
       "      <td>101.522128</td>\n",
       "      <td>103.807993</td>\n",
       "      <td>102.284856</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>111.031669</td>\n",
       "      <td>107.934742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>286</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>145</td>\n",
       "      <td>1112</td>\n",
       "      <td>1242</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>105.047577</td>\n",
       "      <td>103.094185</td>\n",
       "      <td>105.130242</td>\n",
       "      <td>101.542222</td>\n",
       "      <td>103.785191</td>\n",
       "      <td>102.956152</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>106.533680</td>\n",
       "      <td>109.628201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1  TourneyGame  Season  DayNum  Team1  Team2  \\\n",
       "83           83            20            1    2003     137   1104   1231   \n",
       "283         283             1            1    2003     136   1112   1436   \n",
       "284         284            33            1    2003     138   1112   1211   \n",
       "285         285            49            1    2003     143   1112   1323   \n",
       "286         286            57            1    2003     145   1112   1242   \n",
       "\n",
       "     Team1_score  Team2_score WLoc  ...  Team2_avg_opp_avg_opp_avg_opp_avg_oe  \\\n",
       "83            62           67    N  ...                            105.644309   \n",
       "283           80           51    N  ...                            100.841206   \n",
       "284           96           95    N  ...                            102.784377   \n",
       "285           88           71    N  ...                            106.672656   \n",
       "286           75           78    N  ...                            105.047577   \n",
       "\n",
       "     Team2_avg_opp_avg_opp_avg_opp_avg_de  \\\n",
       "83                             100.708799   \n",
       "283                            104.400967   \n",
       "284                            103.030696   \n",
       "285                            100.302686   \n",
       "286                            103.094185   \n",
       "\n",
       "     Team2_opp_avg_opp_avg_opp_avg_opp_avg_oe  \\\n",
       "83                                 105.240340   \n",
       "283                                105.225967   \n",
       "284                                105.106742   \n",
       "285                                105.089853   \n",
       "286                                105.130242   \n",
       "\n",
       "     Team2_opp_avg_opp_avg_opp_avg_opp_avg_de  \\\n",
       "83                                 101.246967   \n",
       "283                                101.301322   \n",
       "284                                101.446902   \n",
       "285                                101.522128   \n",
       "286                                101.542222   \n",
       "\n",
       "     Team2_avg_opp_avg_opp_avg_opp_avg_opp_avg_oe  \\\n",
       "83                                     104.395899   \n",
       "283                                    102.396114   \n",
       "284                                    102.546447   \n",
       "285                                    103.807993   \n",
       "286                                    103.785191   \n",
       "\n",
       "     Team2_avg_opp_avg_opp_avg_opp_avg_opp_avg_de  Team2_Seed  Seed_Diff  \\\n",
       "83                                     102.682732           7          3   \n",
       "283                                    103.091542          16        -15   \n",
       "284                                    103.239985           9         -8   \n",
       "285                                    102.284856           5         -4   \n",
       "286                                    102.956152           2         -1   \n",
       "\n",
       "     t1_pred_oe  t1_pred_de  \n",
       "83   109.064224  109.987823  \n",
       "283  115.220135   99.533473  \n",
       "284  113.888298  105.714808  \n",
       "285  111.031669  107.934742  \n",
       "286  106.533680  109.628201  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['t1_pred_oe', 't1_pred_de']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[feature_list].values\n",
    "y = train['Outcome'].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5365725796673898"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Grid search to get best params\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=9), 'penalty': ['l2', 'l1']}\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "#Use best params to train final model\n",
    "logreg = LogisticRegression(**best_param)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate score on test set \n",
    "y_pred = logreg.predict_proba(X_test)\n",
    "log_loss(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on entire dataset\n",
    "logreg = LogisticRegression(**best_param)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfrom sklearn import svm\\nCs = [0.001, 0.01, 0.1, 1, 10]\\ngammas = [0.001, 0.01, 0.1, 1]\\nparam_grid = {'C': Cs, 'gamma' : gammas}\\nclf = GridSearchCV(svm.SVC(kernel='rbf', probability = True), param_grid, cv=5)\\nclf.fit(X, y)\\nclf.fit(X_train, y_train)\\nbest_param = clf.best_params_\\n\\n\\nsvc_ = svm.SVC(**best_param, probability = True)\\nsvc_.fit(X_train, y_train)\\n\\ny_pred = svc_.predict_proba(X_test)\\nlog_loss(y_test, y_pred)\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "from sklearn import svm\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "clf = GridSearchCV(svm.SVC(kernel='rbf', probability = True), param_grid, cv=5)\n",
    "clf.fit(X, y)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "\n",
    "svc_ = svm.SVC(**best_param, probability = True)\n",
    "svc_.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_.predict_proba(X_test)\n",
    "log_loss(y_test, y_pred)\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5325476914140346"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search to get best params\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "params = {'min_samples_leaf': [50, 75, 100], \n",
    "          'max_depth': [4,5,6,7,8]}\n",
    "\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "#Use best params to train final model\n",
    "rf = RandomForestClassifier(**best_param)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate score on test set \n",
    "y_pred = rf.predict_proba(X_test)\n",
    "log_loss(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=50, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on entire dataset\n",
    "rf = RandomForestClassifier(**best_param)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games.to_csv('output/all_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model/rf.pkl\", \"wb\") as file: \n",
    "    pickle.dump(rf, file)\n",
    "    \n",
    "with open(\"model/logreg.pkl\", \"wb\") as file: \n",
    "    pickle.dump(logreg, file)\n",
    "    \n",
    "with open(\"model/oe_model.pkl\", \"wb\") as file: \n",
    "    pickle.dump(oe_model, file)\n",
    "    \n",
    "with open(\"model/de_model.pkl\", \"wb\") as file: \n",
    "    pickle.dump(de_model, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
