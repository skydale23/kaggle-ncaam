{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-14T23:50:07.234100Z",
     "iopub.status.busy": "2023-03-14T23:50:07.233560Z",
     "iopub.status.idle": "2023-03-14T23:50:08.983773Z",
     "shell.execute_reply": "2023-03-14T23:50:08.983001Z",
     "shell.execute_reply.started": "2023-03-14T23:50:07.234039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MNCAATourneyDetailedResults.csv', 'WNCAATourneySlots.csv', 'MNCAATourneyCompactResults.csv', 'MSeasons.csv', 'first_round_odds_data.csv', 'WTeams.csv', 'MRegularSeasonDetailedResults.csv', 'WNCAATourneyDetailedResults.csv', 'MNCAATourneySlots.csv', 'MGameCities.csv', 'MConferenceTourneyGames.csv', 'WNCAATourneyCompactResults.csv', 'WSeasons.csv', 'Cities.csv', 'WRegularSeasonCompactResults.csv', 'WTeamSpellings.csv', '2024_tourney_seeds.csv', 'WRegularSeasonDetailedResults.csv', 'MRegularSeasonCompactResults.csv', 'WNCAATourneySeeds.csv', 'MNCAATourneySeedRoundSlots.csv', 'WTeamConferences.csv', 'MTeamConferences.csv', 'MTeamCoaches.csv', 'SampleSubmission2023.csv', 'MMasseyOrdinals.csv', 'Conferences.csv', 'MTeams.csv', 'WGameCities.csv', 'MNCAATourneySeeds.csv', 'MSecondaryTourneyTeams.csv', 'MTeamSpellings.csv', 'sample_submission.csv', 'MSecondaryTourneyCompactResults.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "pd.set_option(\"display.max_column\", 999)\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "\n",
    "seeds = pd.read_csv(DATA_PATH + \"MNCAATourneySeeds.csv\")\n",
    "\n",
    "def convert_seeds_to_sample_sub(seeds):\n",
    "\n",
    "        sample_submission = seeds.merge(seeds, on=\"Season\")\n",
    "        sample_submission = sample_submission[[\"Season\", \"TeamID_x\", \"TeamID_y\"]].copy()\n",
    "        sample_submission = sample_submission[sample_submission[\"TeamID_x\"] != sample_submission[\"TeamID_y\"]]\n",
    "        sample_submission[\"ID\"] = np.where(sample_submission[\"TeamID_x\"] < sample_submission[\"TeamID_y\"],\n",
    "                sample_submission[\"Season\"].astype(str) + \"_\" + sample_submission[\"TeamID_x\"].astype(str) + \"_\" + sample_submission[\"TeamID_y\"].astype(str),\n",
    "                sample_submission[\"Season\"].astype(str) + \"_\" +  sample_submission[\"TeamID_y\"].astype(str) + \"_\" + sample_submission[\"TeamID_x\"].astype(str))\n",
    "        sample_submission = sample_submission[[\"Season\", \"ID\"]].copy()\n",
    "\n",
    "        return sample_submission\n",
    "\n",
    "sample_submission = convert_seeds_to_sample_sub(seeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "512dcd34de61fd5e61cd08eccc1c9560362f4178",
    "execution": {
     "iopub.execute_input": "2023-03-14T23:50:10.729373Z",
     "iopub.status.busy": "2023-03-14T23:50:10.728869Z",
     "iopub.status.idle": "2023-03-14T23:50:11.189578Z",
     "shell.execute_reply": "2023-03-14T23:50:11.188462Z",
     "shell.execute_reply.started": "2023-03-14T23:50:10.729322Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    dfswap = df[['Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n",
    "    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n",
    "    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]\n",
    "\n",
    "    dfswap.loc[df['WLoc'] == 'H', 'WLoc'] = 'A'\n",
    "    dfswap.loc[df['WLoc'] == 'A', 'WLoc'] = 'H'\n",
    "    df.columns.values[6] = 'location'\n",
    "    dfswap.columns.values[6] = 'location'    \n",
    "      \n",
    "    df.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(df.columns)]\n",
    "    dfswap.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(dfswap.columns)]\n",
    "\n",
    "    output = pd.concat([df, dfswap]).reset_index(drop=True)\n",
    "    output.loc[output.location=='N','location'] = '0'\n",
    "    output.loc[output.location=='H','location'] = '1'\n",
    "    output.loc[output.location=='A','location'] = '-1'\n",
    "    output.location = output.location.astype(int)\n",
    "    \n",
    "    output['PointDiff'] = output['T1_Score'] - output['T2_Score']\n",
    "    \n",
    "    return output\n",
    "\n",
    "def team_quality(season, regular_season_effects):\n",
    "    formula = 'win~-1+T1_TeamID+T2_TeamID'\n",
    "    glm = sm.GLM.from_formula(formula=formula, \n",
    "                              data=regular_season_effects.loc[regular_season_effects.Season==season,:], \n",
    "                              family=sm.families.Binomial()).fit()\n",
    "    \n",
    "    quality = pd.DataFrame(glm.params).reset_index()\n",
    "    quality.columns = ['TeamID','quality']\n",
    "    quality['Season'] = season\n",
    "    #quality['quality'] = np.exp(quality['quality'])\n",
    "    quality = quality.loc[quality.TeamID.str.contains('T1_')].reset_index(drop=True)\n",
    "    quality['TeamID'] = quality['TeamID'].apply(lambda x: x[10:14]).astype(int)\n",
    "    return quality\n",
    "\n",
    "def cauchyobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    c = 5000 \n",
    "    x =  preds-labels    \n",
    "    grad = x / (x**2/c**2+1)\n",
    "    hess = -c**2*(x**2-c**2)/(x**2+c**2)**2\n",
    "    return grad, hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raddar_pipeline(seeds, regular_results, tourney_results, sub):\n",
    "\n",
    "    regular_results = regular_results.copy()\n",
    "    tourney_results = tourney_results.copy()\n",
    "\n",
    "    print(regular_results.columns)\n",
    "    \n",
    "    regular_data = prepare_data(regular_results)\n",
    "    tourney_data = prepare_data(tourney_results)\n",
    "\n",
    "    boxscore_cols = ['T1_Score', 'T2_Score', \n",
    "        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_FTM', 'T1_FTA', 'T1_OR', 'T1_DR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_Blk', 'T1_PF', \n",
    "        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_FTM', 'T2_FTA', 'T2_OR', 'T2_DR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk', 'T2_PF', \n",
    "        'PointDiff']\n",
    "\n",
    "    boxscore_cols = [\n",
    "            'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_OR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_PF', \n",
    "            'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_OR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk',  \n",
    "            'PointDiff']\n",
    "\n",
    "    funcs = [np.mean]\n",
    "\n",
    "    season_statistics = regular_data.groupby([\"Season\", 'T1_TeamID'])[boxscore_cols].agg(funcs).reset_index()\n",
    "    season_statistics.columns = [''.join(col).strip() for col in season_statistics.columns.values]\n",
    "\n",
    "    season_statistics_T1 = season_statistics.copy()\n",
    "    season_statistics_T2 = season_statistics.copy()\n",
    "\n",
    "    season_statistics_T1.columns = [\"T1_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(season_statistics_T1.columns)]\n",
    "    season_statistics_T2.columns = [\"T2_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(season_statistics_T2.columns)]\n",
    "    season_statistics_T1.columns.values[0] = \"Season\"\n",
    "    season_statistics_T2.columns.values[0] = \"Season\"\n",
    "\n",
    "    tourney_data = tourney_data[['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID' ,'T2_Score']]\n",
    "    tourney_data = pd.merge(tourney_data, season_statistics_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    tourney_data = pd.merge(tourney_data, season_statistics_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    last14days_stats_T1 = regular_data.loc[regular_data.DayNum>118].reset_index(drop=True)\n",
    "    last14days_stats_T1['win'] = np.where(last14days_stats_T1['PointDiff']>0,1,0)\n",
    "    last14days_stats_T1 = last14days_stats_T1.groupby(['Season','T1_TeamID'])['win'].mean().reset_index(name='T1_win_ratio_14d')\n",
    "\n",
    "    last14days_stats_T2 = regular_data.loc[regular_data.DayNum>118].reset_index(drop=True)\n",
    "    last14days_stats_T2['win'] = np.where(last14days_stats_T2['PointDiff']<0,1,0)\n",
    "    last14days_stats_T2 = last14days_stats_T2.groupby(['Season','T2_TeamID'])['win'].mean().reset_index(name='T2_win_ratio_14d')\n",
    "\n",
    "    tourney_data = pd.merge(tourney_data, last14days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    tourney_data = pd.merge(tourney_data, last14days_stats_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    regular_season_effects = regular_data[['Season','T1_TeamID','T2_TeamID','PointDiff']].copy()\n",
    "    regular_season_effects['T1_TeamID'] = regular_season_effects['T1_TeamID'].astype(str)\n",
    "    regular_season_effects['T2_TeamID'] = regular_season_effects['T2_TeamID'].astype(str)\n",
    "    regular_season_effects['win'] = np.where(regular_season_effects['PointDiff']>0,1,0)\n",
    "    march_madness = pd.merge(seeds[['Season','TeamID']],seeds[['Season','TeamID']],on='Season')\n",
    "    march_madness.columns = ['Season', 'T1_TeamID', 'T2_TeamID']\n",
    "    march_madness.T1_TeamID = march_madness.T1_TeamID.astype(str)\n",
    "    march_madness.T2_TeamID = march_madness.T2_TeamID.astype(str)\n",
    "    regular_season_effects = pd.merge(regular_season_effects, march_madness, on = ['Season','T1_TeamID','T2_TeamID'])\n",
    "    glm_quality = pd.concat([\n",
    "                         team_quality(2003, regular_season_effects),\n",
    "                         team_quality(2004, regular_season_effects),\n",
    "                         team_quality(2005, regular_season_effects),\n",
    "                         team_quality(2006, regular_season_effects),\n",
    "                         team_quality(2007, regular_season_effects),\n",
    "                         team_quality(2008, regular_season_effects),\n",
    "                         team_quality(2009, regular_season_effects),\n",
    "                         team_quality(2010, regular_season_effects),\n",
    "                         team_quality(2011, regular_season_effects),\n",
    "                         team_quality(2012, regular_season_effects),\n",
    "                         team_quality(2013, regular_season_effects),\n",
    "                         team_quality(2014, regular_season_effects),\n",
    "                         team_quality(2015, regular_season_effects),\n",
    "                         team_quality(2016, regular_season_effects),\n",
    "                         team_quality(2017, regular_season_effects),\n",
    "                         team_quality(2018, regular_season_effects),\n",
    "                         team_quality(2019, regular_season_effects),\n",
    "                         ##team_quality(2020),\n",
    "                         team_quality(2021, regular_season_effects),\n",
    "                         team_quality(2022, regular_season_effects),\n",
    "                         team_quality(2023, regular_season_effects)\n",
    "                         ]).reset_index(drop=True)\n",
    "\n",
    "                    \n",
    "    glm_quality_T1 = glm_quality.copy()\n",
    "    glm_quality_T2 = glm_quality.copy()\n",
    "    glm_quality_T1.columns = ['T1_TeamID','T1_quality','Season']\n",
    "    glm_quality_T2.columns = ['T2_TeamID','T2_quality','Season']\n",
    "    \n",
    "    tourney_data = pd.merge(tourney_data, glm_quality_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    tourney_data = pd.merge(tourney_data, glm_quality_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    seeds['seed'] = seeds['Seed'].apply(lambda x: int(x[1:3]))\n",
    "\n",
    "    seeds_T1 = seeds[['Season','TeamID','seed']].copy()\n",
    "    seeds_T2 = seeds[['Season','TeamID','seed']].copy()\n",
    "    seeds_T1.columns = ['Season','T1_TeamID','T1_seed']\n",
    "    seeds_T2.columns = ['Season','T2_TeamID','T2_seed']\n",
    "\n",
    "    tourney_data = pd.merge(tourney_data, seeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    tourney_data = pd.merge(tourney_data, seeds_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    tourney_data[\"Seed_diff\"] = tourney_data[\"T1_seed\"] - tourney_data[\"T2_seed\"]\n",
    "\n",
    "    # Build\n",
    "    y = tourney_data['T1_Score'] - tourney_data['T2_Score']\n",
    "\n",
    "    features = list(season_statistics_T1.columns[2:999]) + \\\n",
    "    list(season_statistics_T2.columns[2:999]) + \\\n",
    "    list(seeds_T1.columns[2:999]) + \\\n",
    "    list(seeds_T2.columns[2:999]) + \\\n",
    "    list(last14days_stats_T1.columns[2:999]) + \\\n",
    "    list(last14days_stats_T2.columns[2:999]) + \\\n",
    "    [\"Seed_diff\"] + [\"T1_quality\",\"T2_quality\"]\n",
    "\n",
    "    X = tourney_data[features].values\n",
    "    dtrain = xgb.DMatrix(X, label = y)\n",
    "\n",
    "    param = {} \n",
    "    #param['objective'] = 'reg:linear'\n",
    "    param['eval_metric'] =  'mae'\n",
    "    param['booster'] = 'gbtree'\n",
    "    param['eta'] = 0.05 #change to ~0.02 for final run\n",
    "    param['subsample'] = 0.35\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['num_parallel_tree'] = 3 #recommend 10\n",
    "    param['min_child_weight'] = 40\n",
    "    param['gamma'] = 10\n",
    "    param['max_depth'] =  3\n",
    "    param['silent'] = 1\n",
    "\n",
    "    xgb_cv = []\n",
    "    repeat_cv = 3 # recommend 10\n",
    "\n",
    "    for i in range(repeat_cv): \n",
    "        print(f\"Fold repeater {i}\")\n",
    "        xgb_cv.append(\n",
    "            xgb.cv(\n",
    "            params = param,\n",
    "            dtrain = dtrain,\n",
    "            obj = cauchyobj,\n",
    "            num_boost_round = 3000,\n",
    "            folds = KFold(n_splits = 5, shuffle = True, random_state = i),\n",
    "            early_stopping_rounds = 25,\n",
    "            verbose_eval = 50\n",
    "            )\n",
    "        )\n",
    "    iteration_counts = [np.argmin(x['test-mae-mean'].values) for x in xgb_cv]\n",
    "    val_mae = [np.min(x['test-mae-mean'].values) for x in xgb_cv]\n",
    "\n",
    "    oof_preds = []\n",
    "    for i in range(repeat_cv):\n",
    "        print(f\"Fold repeater {i}\")\n",
    "        preds = y.copy()\n",
    "        kfold = KFold(n_splits = 5, shuffle = True, random_state = i)    \n",
    "        for train_index, val_index in kfold.split(X,y):\n",
    "            dtrain_i = xgb.DMatrix(X[train_index], label = y[train_index])\n",
    "            dval_i = xgb.DMatrix(X[val_index], label = y[val_index])  \n",
    "            model = xgb.train(\n",
    "                params = param,\n",
    "                dtrain = dtrain_i,\n",
    "                num_boost_round = iteration_counts[i],\n",
    "                verbose_eval = 50\n",
    "            )\n",
    "            preds[val_index] = model.predict(dval_i)\n",
    "        oof_preds.append(np.clip(preds,-30,30))\n",
    "\n",
    "    val_cv = []\n",
    "    spline_model = []\n",
    "\n",
    "    for i in range(repeat_cv):\n",
    "        dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n",
    "        dat = sorted(dat, key = lambda x: x[0])\n",
    "        datdict = {}\n",
    "        for k in range(len(dat)):\n",
    "            datdict[dat[k][0]]= dat[k][1]\n",
    "        spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n",
    "        spline_fit = spline_model[i](oof_preds[i])\n",
    "        spline_fit = np.clip(spline_fit,0.025,0.975)\n",
    "        spline_fit[(tourney_data.T1_seed==1) & (tourney_data.T2_seed==16) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n",
    "        spline_fit[(tourney_data.T1_seed==2) & (tourney_data.T2_seed==15) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n",
    "        spline_fit[(tourney_data.T1_seed==3) & (tourney_data.T2_seed==14) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n",
    "        spline_fit[(tourney_data.T1_seed==4) & (tourney_data.T2_seed==13) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n",
    "        spline_fit[(tourney_data.T1_seed==16) & (tourney_data.T2_seed==1) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n",
    "        spline_fit[(tourney_data.T1_seed==15) & (tourney_data.T2_seed==2) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n",
    "        spline_fit[(tourney_data.T1_seed==14) & (tourney_data.T2_seed==3) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n",
    "        spline_fit[(tourney_data.T1_seed==13) & (tourney_data.T2_seed==4) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n",
    "        \n",
    "        val_cv.append(pd.DataFrame({\"y\":np.where(y>0,1,0), \"pred\":spline_fit, \"season\":tourney_data.Season}))\n",
    "        print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") \n",
    "        \n",
    "    val_cv = pd.concat(val_cv)\n",
    "    val_cv.groupby('season').apply(lambda x: log_loss(x.y, x.pred))\n",
    "        \n",
    "    sub['Season'] = sub['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "    sub[\"T1_TeamID\"] = sub['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "    sub[\"T2_TeamID\"] = sub['ID'].apply(lambda x: int(x.split('_')[2]))\n",
    "\n",
    "    sub = pd.merge(sub, season_statistics_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    sub = pd.merge(sub, season_statistics_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    sub = pd.merge(sub, glm_quality_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "\n",
    "    sub = pd.merge(sub, glm_quality_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    sub = pd.merge(sub, seeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    sub = pd.merge(sub, seeds_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "    sub = pd.merge(sub, last14days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "    sub = pd.merge(sub, last14days_stats_T2, on = ['Season', 'T2_TeamID'], how = 'left')\n",
    "\n",
    "    sub[\"Seed_diff\"] = sub[\"T1_seed\"] - sub[\"T2_seed\"]\n",
    "\n",
    "    Xsub = sub[features].values\n",
    "    dtest = xgb.DMatrix(Xsub)\n",
    "\n",
    "    sub_models = []\n",
    "    for i in range(repeat_cv):\n",
    "        print(f\"Fold repeater {i}\")\n",
    "        sub_models.append(\n",
    "            xgb.train(\n",
    "            params = param,\n",
    "            dtrain = dtrain,\n",
    "            num_boost_round = int(iteration_counts[i] * 1.05),\n",
    "            verbose_eval = 50\n",
    "            )\n",
    "        )\n",
    "\n",
    "    sub_preds = []\n",
    "    for i in range(repeat_cv):\n",
    "        sub_preds.append(np.clip(spline_model[i](np.clip(sub_models[i].predict(dtest),-30,30)),0.025,0.975))\n",
    "        \n",
    "    sub[\"Pred\"] = pd.DataFrame(sub_preds).mean(axis=0)\n",
    "    return sub[['ID','Pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "01757a38a0ad222dec31bf062ceee7cfb61a6b16",
    "execution": {
     "iopub.execute_input": "2023-03-14T23:51:39.126405Z",
     "iopub.status.busy": "2023-03-14T23:51:39.126124Z",
     "iopub.status.idle": "2023-03-14T23:51:45.625662Z",
     "shell.execute_reply": "2023-03-14T23:51:45.624777Z",
     "shell.execute_reply.started": "2023-03-14T23:51:39.126369Z"
    }
   },
   "outputs": [],
   "source": [
    "# preds_2023 = raddar_pipeline(seeds, regular_results, tourney_results[tourney_results != 2023], sample_submission[sample_submission.Season == 2023])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_2023.to_csv(\"../submissions/raddar_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_results = pd.concat([\n",
    "pd.read_csv(DATA_PATH + \"MNCAATourneyDetailedResults.csv\"),\n",
    "pd.read_csv(DATA_PATH + \"WNCAATourneyDetailedResults.csv\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "seeds = pd.concat([\n",
    "    pd.read_csv(DATA_PATH + \"MNCAATourneySeeds.csv\"),\n",
    "    pd.read_csv(DATA_PATH + \"WNCAATourneySeeds.csv\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "regular_results = pd.concat([\n",
    "    pd.read_csv(DATA_PATH + \"MRegularSeasonDetailedResults.csv\"),\n",
    "    pd.read_csv(DATA_PATH + \"WRegularSeasonDetailedResults.csv\"),\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_results_in = tourney_results.copy()\n",
    "regular_results_in = regular_results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
      "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
      "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skylerdale/.virtualenvs/ncaa_model/lib/python3.8/site-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    }
   ],
   "source": [
    "all_raddar_preds = []\n",
    "\n",
    "for s in range(2010, 2024):\n",
    "    print(s)\n",
    "    preds = raddar_pipeline(seeds, regular_results_in.copy(), tourney_results_in[tourney_results_in[\"Season\"] < int(s)].copy(), sample_submission[sample_submission.Season == s].copy())\n",
    "    all_raddar_preds.append(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncaa_model",
   "language": "python",
   "name": "ncaa_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
