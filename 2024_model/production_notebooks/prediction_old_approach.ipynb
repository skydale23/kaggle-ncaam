{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../kaggle_prediction_library/') \n",
    "import preprocess\n",
    "import feature_engineering\n",
    "import submission\n",
    "import validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from hyperopt import tpe, fmin, Trials\n",
    "# import hyperopt.hp as hp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict_mens = pd.read_csv(\"to_predict_mens.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(to_predict_mens, season):\n",
    "\n",
    "    to_predict_mens_train = to_predict_mens[(to_predict_mens.Season < season)].copy()\n",
    "    \n",
    "    to_predict_mens_test = to_predict_mens[(to_predict_mens.Season == season)].copy()\n",
    "    \n",
    "    return to_predict_mens_train, to_predict_mens_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_statistics_model(to_predict_mens_train, statistics_features):\n",
    "\n",
    "    best_params = {\"C\": .1}\n",
    "    model = LogisticRegression(**best_params)\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    statistics_model = pipeline.fit(to_predict_mens_train[statistics_features], to_predict_mens_train[\"Outcome\"])\n",
    "\n",
    "    return statistics_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(to_predict_test, statistics_model, features):\n",
    "\n",
    "    pred_proba = statistics_model.predict_proba(to_predict_test[features].copy())[:,1]\n",
    "    to_predict_test[\"Pred\"] = pred_proba\n",
    "    mens_sub = to_predict_test[[\"ID\", \"Pred\"]]\n",
    "    \n",
    "    return mens_sub\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(to_predict_mens, season, statistics_features):\n",
    "    \n",
    "    # get data\n",
    "    to_predict_mens_train, to_predict_test= prepare_data(to_predict_mens, season)\n",
    "    \n",
    "    # train\n",
    "    statistics_model = train_statistics_model(to_predict_mens_train, statistics_features)\n",
    "\n",
    "    # inference\n",
    "    sub = inference(to_predict_test, statistics_model, statistics_features) \n",
    "\n",
    "    return sub\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_features = ['t1_adj_margin', 't2_adj_margin', 't1_final_rank', 't2_final_rank', 't1_OrdinalRank', 't2_OrdinalRank']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_subs = []\n",
    "\n",
    "for year in range(2010, 2024):\n",
    "    if year != 2020:\n",
    "        sub = run(to_predict_mens, year, statistics_features)\n",
    "        all_subs.append(sub)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = pd.concat(all_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs.to_csv(\"../submissions/all_sky_model_preds_old.csv\")\n",
    "\n",
    "#mens_sub.to_csv(\"../submissions/sub_2023_in_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncaa_model",
   "language": "python",
   "name": "ncaa_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
