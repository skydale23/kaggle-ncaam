{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed data\n",
    "all_games = pd.read_csv('../feature_engineering/output/all_games.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>avg_rank_x</th>\n",
       "      <th>t1_final_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_OrdinalRank</th>\n",
       "      <th>t1_pre_season_top_25_flag</th>\n",
       "      <th>t2_OrdinalRank</th>\n",
       "      <th>t2_pre_season_top_25_flag</th>\n",
       "      <th>t1_adj_oe_0</th>\n",
       "      <th>t1_adj_de_0</th>\n",
       "      <th>t2_adj_oe_0</th>\n",
       "      <th>t2_adj_de_0</th>\n",
       "      <th>t1_adj_margin</th>\n",
       "      <th>t2_adj_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1104_1231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1104</td>\n",
       "      <td>1231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>83.919965</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.816081</td>\n",
       "      <td>99.352800</td>\n",
       "      <td>117.504767</td>\n",
       "      <td>102.675920</td>\n",
       "      <td>14.46328</td>\n",
       "      <td>14.828846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1112_1436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1112</td>\n",
       "      <td>1436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95.514642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.071254</td>\n",
       "      <td>93.286794</td>\n",
       "      <td>106.884988</td>\n",
       "      <td>101.850357</td>\n",
       "      <td>25.78446</td>\n",
       "      <td>5.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1112_1211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1112</td>\n",
       "      <td>1211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95.514642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.071254</td>\n",
       "      <td>93.286794</td>\n",
       "      <td>119.060818</td>\n",
       "      <td>103.143440</td>\n",
       "      <td>25.78446</td>\n",
       "      <td>15.917378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1112_1323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1112</td>\n",
       "      <td>1323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95.514642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.071254</td>\n",
       "      <td>93.286794</td>\n",
       "      <td>123.511353</td>\n",
       "      <td>99.574998</td>\n",
       "      <td>25.78446</td>\n",
       "      <td>23.936355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1112_1242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>1112</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95.514642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.071254</td>\n",
       "      <td>93.286794</td>\n",
       "      <td>121.830222</td>\n",
       "      <td>88.607589</td>\n",
       "      <td>25.78446</td>\n",
       "      <td>33.222633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type              ID  Pred  Season  Team1  Team2  Outcome  \\\n",
       "0           0     0  2003_1104_1231   NaN    2003   1104   1231      0.0   \n",
       "1           1     0  2003_1112_1436   NaN    2003   1112   1436      1.0   \n",
       "2           2     0  2003_1112_1211   NaN    2003   1112   1211      1.0   \n",
       "3           3     0  2003_1112_1323   NaN    2003   1112   1323      1.0   \n",
       "4           4     0  2003_1112_1242   NaN    2003   1112   1242      0.0   \n",
       "\n",
       "   avg_rank_x  t1_final_rank  ...  t1_OrdinalRank  t1_pre_season_top_25_flag  \\\n",
       "0          36      83.919965  ...             2.0                        1.0   \n",
       "1           2      95.514642  ...             1.0                        1.0   \n",
       "2           2      95.514642  ...             1.0                        1.0   \n",
       "3           2      95.514642  ...             1.0                        1.0   \n",
       "4           2      95.514642  ...             1.0                        1.0   \n",
       "\n",
       "   t2_OrdinalRank  t2_pre_season_top_25_flag  t1_adj_oe_0  t1_adj_de_0  \\\n",
       "0             7.0                        1.0   113.816081    99.352800   \n",
       "1            25.0                        NaN   119.071254    93.286794   \n",
       "2            25.0                        NaN   119.071254    93.286794   \n",
       "3            10.0                        1.0   119.071254    93.286794   \n",
       "4            20.0                        1.0   119.071254    93.286794   \n",
       "\n",
       "   t2_adj_oe_0  t2_adj_de_0  t1_adj_margin  t2_adj_margin  \n",
       "0   117.504767   102.675920       14.46328      14.828846  \n",
       "1   106.884988   101.850357       25.78446       5.034632  \n",
       "2   119.060818   103.143440       25.78446      15.917378  \n",
       "3   123.511353    99.574998       25.78446      23.936355  \n",
       "4   121.830222    88.607589       25.78446      33.222633  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tournament games we are predicting on \n",
    "#all_games = all_games[(all_games.Season < 2015)] #this is for the first stage\n",
    "all_games = all_games[(all_games.Season < 2021)] #this is for the second stage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['seed_diff',  \n",
    "                't1_adj_margin','t2_adj_margin',\n",
    "                't1_final_rank', 't2_final_rank',\n",
    "                't1_OrdinalRank', 't2_OrdinalRank']\n",
    " \n",
    "#feature_list = ['t1_adj_oe', 't2_adj_oe', 't1_adj_de', 't2_adj_de', 't1_adj_oe_120_999', 't2_adj_oe_120_999', 't1_adj_de_120_999', 't2_adj_de_120_999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = all_games.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_games[feature_list].values\n",
    "y = all_games['Outcome'].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search to get best params\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=9), 'penalty': ['l2', 'l1']}\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "#Use best params to train final model\n",
    "logreg = LogisticRegression(**best_param)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate score on test set \n",
    "#y_pred = logreg.predict_proba(X_test)\n",
    "#log_loss(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Pipeline([('scale', StandardScaler()),('logreg', LogisticRegression(**best_param))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. log loss: 0.5331328714919731\n",
      "min log loss: 0.4547420312777294\n",
      "max log loss: 0.6303449646777416\n",
      "std dev log loss: 0.04752104247517444\n",
      "[0.529220101762317, 0.5443582052394548, 0.5080717377142734, 0.5572415432057151, 0.4547420312777294, 0.47616196332436883, 0.48627577534272454, 0.5330373560797379, 0.6303449646777416, 0.5565531736203815, 0.5709090551306233, 0.5790752481962138, 0.495522004882169, 0.547662832627855, 0.5063954108479968, 0.603377326699413, 0.484310084734829]\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "seasons = list(all_games.Season.unique())\n",
    "\n",
    "log_loss_list = []\n",
    "\n",
    "for test_season in seasons:\n",
    "    \n",
    "    train_seasons = seasons.copy()\n",
    "    train_seasons.remove(test_season)\n",
    " \n",
    "    X_train = all_games[all_games['Season'].isin(train_seasons)][feature_list].values\n",
    "    X_test = all_games[all_games.Season == test_season][feature_list].values\n",
    "\n",
    "    y_train = all_games[all_games['Season'].isin(train_seasons)]['Outcome'].values.ravel()\n",
    "    y_test = all_games[all_games.Season == test_season]['Outcome'].values.ravel()\n",
    "    \n",
    "    logreg = LogisticRegression(**best_param)\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    #Evaluate score on test set \n",
    "    y_pred = logreg.predict_proba(X_test)\n",
    "    \n",
    "    ll = log_loss(y_test, y_pred)\n",
    "    log_loss_list.append(ll)\n",
    "    \n",
    "    \n",
    "print('avg. log loss: {}'.format(sum(log_loss_list) / len(log_loss_list)))\n",
    "print('min log loss: {}'.format(min(log_loss_list)))\n",
    "print('max log loss: {}'.format(max(log_loss_list)))\n",
    "print('std dev log loss: {}'.format(statistics.stdev(log_loss_list)))\n",
    "print(log_loss_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on entire dataset\n",
    "logreg = LogisticRegression(**best_param)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg. log loss: 0.5377196208726289\n",
    "min log loss: 0.4527681615412048\n",
    "max log loss: 0.6301372973190598\n",
    "std dev log loss: 0.04826156092665253\n",
    "[0.5229902686047858, 0.5236486146281775, 0.5158111793350595, 0.56923309326896, 0.4527681615412048, 0.483523972814316, 0.5005711494650689, 0.5390678057159176, 0.6301372973190598, 0.562545719196487, 0.5826151696256913, 0.5697230189568193]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search to get best params\n",
    "clf = XGBClassifier(random_state = 0)\n",
    "\n",
    "params = {'min_child_weight': [5],\n",
    "        'gamma': [5, 10],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.4, 0.6],\n",
    "        'max_depth': [1, 2, 3, 10, 20, 30, 50]\n",
    "        }\n",
    "\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'colsample_bytree': 0.8,                 \n",
    "              'learning_rate': 0.0003,\n",
    "              'max_depth': 5,\n",
    "              'subsample': 1,\n",
    "              'objective':'binary:logistic',\n",
    "              'eval_metric':'logloss',\n",
    "              'min_child_weight':3,\n",
    "              'gamma':0.25,\n",
    "              'n_estimators':500,\n",
    "              'verbosity':5\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. log loss: 0.6614626711755712\n",
      "min log loss: 0.6542309042997658\n",
      "max log loss: 0.670325395331454\n",
      "std dev log loss: 0.005667239934436234\n",
      "[0.6589280436746776, 0.6597465183585882, 0.6566117340698838, 0.6678383476100862, 0.654261922929436, 0.6572385858744383, 0.6542309042997658, 0.6642895918339491, 0.669623213472651, 0.6609168021536586, 0.6635409944982671, 0.670325395331454]\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "seasons = list(all_games.Season.unique())\n",
    "\n",
    "log_loss_list = []\n",
    "\n",
    "for test_season in seasons:\n",
    "    \n",
    "    train_seasons = seasons.copy()\n",
    "    train_seasons.remove(test_season)\n",
    " \n",
    "    X_train = all_games[all_games['Season'].isin(train_seasons)][feature_list].values\n",
    "    X_test = all_games[all_games.Season == test_season][feature_list].values\n",
    "\n",
    "    y_train = all_games[all_games['Season'].isin(train_seasons)]['Outcome'].values.ravel()\n",
    "    y_test = all_games[all_games.Season == test_season]['Outcome'].values.ravel()\n",
    "    \n",
    "    clf = XGBClassifier(**best_param)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Evaluate score on test set \n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    ll = log_loss(y_test, y_pred)\n",
    "    log_loss_list.append(ll)\n",
    "    \n",
    "    \n",
    "print('avg. log loss: {}'.format(sum(log_loss_list) / len(log_loss_list)))\n",
    "print('min log loss: {}'.format(min(log_loss_list)))\n",
    "print('max log loss: {}'.format(max(log_loss_list)))\n",
    "print('std dev log loss: {}'.format(statistics.stdev(log_loss_list)))\n",
    "print(log_loss_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg. log loss: 0.5382626508307115\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 1618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfrom sklearn import svm\\nCs = [0.001, 0.01, 0.1, 1, 10]\\ngammas = [0.001, 0.01, 0.1, 1]\\nparam_grid = {'C': Cs, 'gamma' : gammas}\\nclf = GridSearchCV(svm.SVC(kernel='rbf', probability = True), param_grid, cv=5)\\nclf.fit(X, y)\\nclf.fit(X_train, y_train)\\nbest_param = clf.best_params_\\n\\n\\nsvc_ = svm.SVC(**best_param, probability = True)\\nsvc_.fit(X_train, y_train)\\n\\ny_pred = svc_.predict_proba(X_test)\\nlog_loss(y_test, y_pred)\\n\""
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "from sklearn import svm\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "clf = GridSearchCV(svm.SVC(kernel='rbf', probability = True), param_grid, cv=5)\n",
    "clf.fit(X, y)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "\n",
    "svc_ = svm.SVC(**best_param, probability = True)\n",
    "svc_.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_.predict_proba(X_test)\n",
    "log_loss(y_test, y_pred)\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. log loss: 0.531922722936705\n",
      "min log loss: 0.4445775307006808\n",
      "max log loss: 0.6229365622303814\n",
      "std dev log loss: 0.048389749307892846\n",
      "[0.5226171255883458, 0.5260895194839206, 0.5105384202401526, 0.5587125165429248, 0.4445775307006808, 0.47792357220814596, 0.4882708443748359, 0.5332024572220709, 0.6229365622303814, 0.5538069505726807, 0.5733605436225888, 0.5710366324537309]\n"
     ]
    }
   ],
   "source": [
    "#Grid search to get best params\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "params = {'min_samples_leaf': [1, 5, 15, 25, 50, 80, 100], \n",
    "          'bootstrap': [True, False],\n",
    "          'max_depth': [1, 3, 5, 10, 20, None],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "         }\n",
    "\n",
    "clf = GridSearchCV(clf, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "best_param = clf.best_params_\n",
    "\n",
    "#Cross validation\n",
    "seasons = list(all_games.Season.unique())\n",
    "\n",
    "log_loss_list = []\n",
    "\n",
    "for test_season in seasons:\n",
    "    \n",
    "    train_seasons = seasons.copy()\n",
    "    train_seasons.remove(test_season)\n",
    " \n",
    "    X_train = all_games[all_games['Season'].isin(train_seasons)][feature_list].values\n",
    "    X_test = all_games[all_games.Season == test_season][feature_list].values\n",
    "\n",
    "    y_train = all_games[all_games['Season'].isin(train_seasons)]['Outcome'].values.ravel()\n",
    "    y_test = all_games[all_games.Season == test_season]['Outcome'].values.ravel()\n",
    "    \n",
    "    rf = RandomForestClassifier(**best_param)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Evaluate score on test set \n",
    "    y_pred = logreg.predict_proba(X_test)\n",
    "    \n",
    "    ll = log_loss(y_test, y_pred)\n",
    "    log_loss_list.append(ll)\n",
    "    \n",
    "    \n",
    "print('avg. log loss: {}'.format(sum(log_loss_list) / len(log_loss_list)))\n",
    "print('min log loss: {}'.format(min(log_loss_list)))\n",
    "print('max log loss: {}'.format(max(log_loss_list)))\n",
    "print('std dev log loss: {}'.format(statistics.stdev(log_loss_list)))\n",
    "print(log_loss_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=25, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=80, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on entire dataset\n",
    "rf = RandomForestClassifier(**best_param)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_games.to_csv('output/all_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "with open(\"model/logreg.pkl\", \"wb\") as file: \n",
    "    pickle.dump(logreg, file)\n",
    "\n",
    "#with open(\"model/rf.pkl\", \"wb\") as file: \n",
    " #   pickle.dump(rf, file)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
